\section{Related Work}
    In recent times, there have been several studies done on the algorithms and frameworks to study federated learning. \textbf{FedProx} is an optimized version of the Federated Average algorithm that is more robust than the original, especially in case of highly heterogenous settings. \textbf{FedAdaptive} presents federated versions of adaptive optimizers such as Adam and Adagrad. These advances in the FL framework have mostly leveraged the \textbf{LEAF} simulation framework. Few works have performed evaluations on real-world devices. A recent paper in 2022 \textbf{“An Experiment Study on Federated Learning Testbed”} performance of federated learning on IOT devices is an example in that direction. Similarly, the paper \textbf{"Optimize Scheduling of Federated Learning on Battery-powered Mobile Devices"} utilized a testbed of 4 devices with varying CPU cores and processing capabilities to to evaluate their approach using the MNIST dataset. To facilitate experiments on real devices, \textbf{Flower} a highly developed framework has been introduced that can support millions of real world clients using just a few high end GPUs.

% reference deployed FL applications
% papers evaluated on testbed of real devices